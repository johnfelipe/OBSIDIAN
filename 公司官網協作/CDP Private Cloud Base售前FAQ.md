# 什麼是Hadoop？
>「一個便當吃不飽，可以吃兩個啊！」

當企業儲存的資料越來越多，若是增加個幾TB可以加裝硬碟進行擴容，但是增加個幾百TB的資料，顯然不是一台電腦主機就裝得下。那麼要怎麼樣把資料放到多台主機，又能夠**同時使用與管理裡面的資料**呢？Hadoop就此應運而生！既然一台電腦裝不下，那麼可以放到兩台，甚至更多台主機裡面囉！
Hadoop目前是Apache的開源專案，有著各式各樣的開源應用程式，儼然是個豐富的生態系。
# Hadoop可以做什麼？
Hadoop File System，簡稱HDFS，是一種分散式檔案系統，可以整合多台主機的儲存空間來存放資料。HDFS在存放檔案有自己獨特的邏輯，他會將一整個的檔案切成小塊做上記號，然後製作副本，散佈到不同的主機上。這麼做有幾個好處：
- 當要讀取或寫入時，因為檔案被切分成小塊，壓力分散到多台主機，妥善運用資源，避免一台主機存放一個超大檔案，造成I/O擠在一台電腦上陷入瓶頸，其他主機卻閒得發慌。
- 每個小塊都有自己的副本，雖然會花費更多儲存空間，但是當中一個主機意外故障時，存在其他地方的副本，馬上可以提供資料，HDFS也會自動把缺少的副本補齊。

Yet Another Resource Negotiator，簡稱YARN，是一種分散式運算系統，可以統籌多台主機的運算資源來進行計算。傳統上使用MapReduce運算框架，可以處理存放在HDFS中的大量資料。
有了基礎的檔案與運算系統，開始有許多的應用依附著Hadoop，常見的有：
- Apache Hive主要用於資料倉儲，適合巨量資料的批量處理
- Apache HBase作為No-SQL的資料庫，提供更即時的搜尋
- Apache Kafka流式資料訊息傳遞中介，為資料流解耦
- Apache Spark資料分析工具，提供資料探勘與機器學習的API
- 族繁不及備載...
# Hadoop與資料庫有什麼不同？為什麼Hive查資料那麼慢？
Hadoop是將資料存放在分散式檔案系統，所以可以存放各種檔案。Apache Hive則是提供類似傳統關連式資料庫的介面，讓使用者可以使用近似SQL的指令HiveQL，將大量的結構化資料存入HDFS中進行「資料倉儲」。由於使用Hive的主要目的是存放大量資料，必要時才使用YARN進行存取與運算，傳統上Hive使用MapReduce運算框架，運算過程中大量使用硬碟I/O，繞過記憶體昂貴而造成OOM麻煩，更多用於**巨量資料的批次處理**。因此，相較用在OLTP追求速度而大量使用記憶體的資料庫，速度會慢上許多。
若是要更即時的互動式查詢，可以使用Apache Impala來訪問Hive中的資料，Impala繞過YARN與MapReduce，有著更快的反應速度。
# 什麼是CDP Private Cloud Base？
Apache Hadoop生態豐富，要合宜地將各個服務部署到叢集中，手續就變得相當複雜複雜，不同的應用彼此相互依賴，其中的各個參數互相影響，也需要第三方軟體來來間來監視每個服務的狀態。Cloudera的CDP Private Cloud Base就是上述難題的解決方案，它整合了Hadoop生態系中常用的應用服務，它的Cloudera Manager提供Web UI方便管理者部署，也能夠集中管理，包括起停服務、調校設定檔參數、套用安全策略等，省去手動操作的麻煩或編寫腳本的開發過程，讓企業可以更快速更方便地開始資料分析，讓大數據為企業帶來的價值。
